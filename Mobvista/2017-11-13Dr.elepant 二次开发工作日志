---
title: 2017-11-13Dr.elepant 二次开发工作日志
tags: mobvista
grammar_cjkRuby: true
---


* 清空`app-conf/elephant.conf`中配置对应的数据库
```shell
db_url=""
db_name=drelephant
db_user=dataplatform
db_password=""
```
* 执行./compile.sh complie.conf
* 生成dist目录，将zip压缩文件上传到线上，解压
* 解压之后，进入`bin`目录，执行./start.sh ../app-conf
* 结束可直接执行./stop.sh
* 代码正常执行的状态会打印到项目根目录的dr.log
* 代码内部的log会打印到项目上一级目录的log目录下

bugfix:
1. dashbord正常显示
	bug2修复之后，即正常显示。
2. 多线程逻辑保证正常
	问题出现原因：
	* 多线程注意static，final关键字的使用，二者一旦修饰了多线程共用的变量，在之后的更改操作都是不合法的。
	* 在for循环中进行赋值操作，切忌使用单例对象进行赋值，使用单例引用，依次赋值给多个引用，一旦单例发生改变，就会使多个变量的值全部被覆盖成单例最后的值，foreach中也要注意foreach指定的是一个引用，使用这个引用进行赋值操作也是不可取的。
	* retryQueue存在多线程的问题？总是出现jobId和jobhistoryaddr不对应的问题： 
		* 去掉final以待观察，防止队列中的jobId被其他集群的线程共享
		* final确实阻止了新建的生成器对象中没有自己的retryQueue,但去掉final仍不能解决问题。
	* MapReduceFetcher中的historyaddr会被上一个使用过它的集群线程所更改，当多个集群并发调用，就会爆发线程安全问题，historyaddr会被频繁的更改。
		* 将Fetcher公用的变量放入到方法内部，转换为局部变量。
	* DB Connection提前关闭，排除数据库连接时间超时，需要去寻找Ebean对数据库连接的管理。//TODO
	
	
3. spark 兼容2.0.1
	spark日志文件路径：
	
	mob_m_online:                           webhdfs://ip-172-31-29-202.ec2.internal:50070/var/log/spark/apps/
	mob_emr_online_autoscaling:   webhdfs://ip-172-31-31-107.ec2.internal:50070/var/log/spark/apps/
	mob_emr_offline:                       wehdfs://ip-172-31-30-48.ec2.internal:50070/var/log/spark/apps/
	wayio:                                         webhdfs://ip-172-31-26-99.ec2.internal:50070/var/log/spark/apps/
	mob_3s_online:	                        webhdfs://ip-172-31-30-45.ec2.internal:50070/var/log/spark/apps/
	mob_emr_online_spark_2.0.0:	 webhdfs://ip-172-31-8-98.ec2.internal:50070/var/log/spark/apps/
	mob_3s_offline:	                         webhdfs://ip-172-31-29-42.ec2.internal:50070/var/log/spark/apps/
	mob_data_offline:	                    webhdfs://ip-172-31-27-152.ec2.internal:50070/var/log/spark/apps/
	mob_analyse_offline: 	             webhdfs://ip-172-31-18-92.ec2.internal:50070/var/log/spark/apps/
	mob_m_offline:	                        webhdfs://ip-172-31-16-216.ec2.internal:50070/var/log/spark/apps/
	dr.elephant FSFetcher会对有attempt 和 codec的文件，自动拼接新的路径，并获取Codec,去处理指定的压缩文件流
	目前无法读取新产出的日志文件，原因：permission denied
	日志限制块大小：500MB
	bugfix:切换到hadoop用户下执行
4. 添加search查询表单的ClusterName的查询选项

反复测试发现每次对相同的Application ，出现SQL异常
mob_analyse_offline
application_1500623177035_19940
application_1500623177035_19941
application_1500623177035_19942
application_1500623177035_19734
application_1500623177035_19735

mob_emr_online_autoscaling:
application_1496798446986_1191012
application_1496798446986_1191010
application_1496798446986_1191015
application_1496798446986_1191019
application_1496798446986_1191006
application_1496798446986_1191004
application_1496798446986_1191003

application_1496798446986_1190997
application_1496798446986_1190976
application_1496798446986_1190968
application_1496798446986_1190982
application_1496798446986_1190987
application_1496798446986_1190985
application_1496798446986_1190964
application_1496798446986_1190962
application_1496798446986_1190968
 
 SQL State = HY000  数据插入异常
<logger name="org.avaje.ebean.SQL" level="TRACE" />
ebean log打印SQL
bugfix：每个建表语句后添加ENGINE=InnoDB DEFAULT CHARSET=UTF8修复问题

5. spark 收集的Heuristic不全//TODO bugfix
6. MySQL查询将结果以表格的形式发邮件。//TODO 



 


